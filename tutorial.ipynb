{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "Upload needed libraries and setting up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bellatrex version: 0.3.1\n",
      "c:\\Users\\KlestDedja\\Documents\\GitHub\\Bellatrex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import bellatrex as btrex\n",
    "print(\"Bellatrex version:\", btrex.__version__)\n",
    "\n",
    "PLOT_GUI = False\n",
    "\n",
    "##########################################################################\n",
    "root_folder = os.getcwd()\n",
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from bellatrex.datasets import load_mtr_data, load_mlc_data\n",
    "from bellatrex.datasets import load_survival_data, load_binary_data, load_regression_data\n",
    "from bellatrex.utilities import get_auto_setup\n",
    "\n",
    "# X, y = load_binary_data(return_X_y=True)\n",
    "# X, y = load_regression_data(return_X_y=True)\n",
    "# X, y = load_survival_data(return_X_y=True)\n",
    "X, y = load_mlc_data(return_X_y=True)\n",
    "# X, y = load_mtr_data(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the prediction task, we train a compatible Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected prediction task 'SETUP': multi-label\n",
      "Model fitting complete.\n"
     ]
    }
   ],
   "source": [
    "SETUP = get_auto_setup(y) # not necessary, but comfortable while swithcing between mnay prediction tasks\n",
    "print('Detected prediction task \\'SETUP\\':', SETUP)\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "### instantiate original R(S)F estimator, works best with some pruning.\n",
    "if SETUP.lower() in 'survival':\n",
    "    clf = RandomSurvivalForest(n_estimators=100, min_samples_split=10,\n",
    "                                n_jobs=-2, random_state=0)\n",
    "\n",
    "elif SETUP.lower() in ['binary', 'multi-label']:\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=5,\n",
    "                                n_jobs=-2, random_state=0)\n",
    "\n",
    "elif SETUP.lower() in ['regression', 'multi-target']:\n",
    "    clf = RandomForestRegressor(n_estimators=100, min_samples_split=5,\n",
    "                                n_jobs=-2, random_state=0)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('Model fitting complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the RF model to be explained is already trained externally, it can be loaded and packed with the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bellatrex.wrapper_class import pack_trained_ensemble\n",
    "\n",
    "# Pretrained RF model should be packed as a list of dicts with the function below.\n",
    "clf_packed = pack_trained_ensemble(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `pack_trained_ensemble` stores a memory-efficient version of the model, making the model \n",
    "compatible not only with Bellatrex but also with [SHAP](https://shap.readthedocs.io/en/latest/)\n",
    "\n",
    "The packed `clf_packed` model can now be passed into Bellatrex.\n",
    "\n",
    "## Building Explanations\n",
    "Now we can fit Bellatrex on the training data and run it on a few test samples\n",
    "After fitting and tuning the explainer to a specific test instance, you can:\n",
    "- `plot_overview()` to get a representation of the tree learners, and of the selected rules;\n",
    "    GUI is available for this plotting method (set the paramter `plot_gui = True`).\n",
    "- `plot_visuals()` to visualise the selected rules in a more use friendly way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is already fitted, building explanation.\n",
      "oracle_sample is: None\n",
      "Automatically setting prediction task to: multi-label\n",
      "Explaining sample i=0\n",
      "best params: {'n_clusters': 2, 'n_dims': None, 'n_trees': 60}\n",
      "Achieved fidelity: 0.7454\n",
      "final trees indices: [20  1]\n",
      "final cluster sizes: [29 31]\n",
      "Bellatrex prediction: 0.613, 0.500, 0.129, 0.000, 1.000, 0.000, 0.000\n",
      "Black box prediction: 0.669, 0.503, 0.309, 0.048, 0.855, 0.054, 0.054\n",
      "##########################################################\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "plot_visuals() is compatible with single-output tasks only,\nfound 'multi-label'. Use plot_overview() instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     18\u001b[39m tuned_method = Btrex_fitted.explain(X_test, i)\n\u001b[32m     20\u001b[39m fig1, axs1 = tuned_method.plot_overview(plot_gui=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     21\u001b[39m                            show=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m fig2, axs2 = \u001b[43mtuned_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_visuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_max_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mpreds_distr\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mconf_level\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mtot_digits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m plt.show(fig1)\n\u001b[32m     28\u001b[39m plt.show(fig2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\Bellatrex\\app\\bellatrex\\bellatrex_explain.py:636\u001b[39m, in \u001b[36mBellatrexExplain.plot_visuals\u001b[39m\u001b[34m(self, plot_max_depth, preds_distr, conf_level, tot_digits, b_box_pred, keep_files, out_file, show)\u001b[39m\n\u001b[32m    633\u001b[39m multi_output_cases = tuned_method.MSA_KEYS + tuned_method.MTC_KEYS + tuned_method.MTR_KEYS\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tuned_method.set_up \u001b[38;5;129;01min\u001b[39;00m multi_output_cases:\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    637\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mplot_visuals() is compatible with single-output tasks only,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    638\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfound \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtuned_method.set_up\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use plot_overview() instead\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    639\u001b[39m     )\n\u001b[32m    641\u001b[39m out_file, file_extra = \u001b[38;5;28mself\u001b[39m.create_rules_txt()\n\u001b[32m    642\u001b[39m rules, preds, baselines, weights, other_preds = read_rules(\n\u001b[32m    643\u001b[39m     file=out_file, file_extra=file_extra\n\u001b[32m    644\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: plot_visuals() is compatible with single-output tasks only,\nfound 'multi-label'. Use plot_overview() instead"
     ]
    }
   ],
   "source": [
    "from bellatrex import BellatrexExplain\n",
    "from bellatrex.utilities import predict_helper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fit RF here. The hyperparameters for fitting the explanation are given\n",
    "# compatible with trained ensemble model clf, and with packed dictionary as in clf_packed\n",
    "Btrex_fitted = BellatrexExplain(clf_packed, set_up='auto',\n",
    "                                p_grid={\"n_clusters\": [1, 2, 3]},\n",
    "                                verbose=3).fit(X_train, y_train)\n",
    "\n",
    "N_TEST_SAMPLES = 2\n",
    "for i in range(N_TEST_SAMPLES):\n",
    "\n",
    "    print(f\"Explaining sample i={i}\")\n",
    "\n",
    "    y_train_pred = predict_helper(clf, X_train) # calls, predict or predict_proba, depending on the underlying model\n",
    "\n",
    "    tuned_method = Btrex_fitted.explain(X_test, i)\n",
    "\n",
    "    fig1, axs1 = tuned_method.plot_overview(plot_gui=False,\n",
    "                               show=True)\n",
    "    plt.show(fig1)\n",
    "\n",
    "    if SETUP.lower() in ['binary', 'regresssion', 'survival']:\n",
    "\n",
    "        fig2, axs2 = tuned_method.plot_visuals(plot_max_depth=5,\n",
    "                              preds_distr=y_train_pred,\n",
    "                              conf_level=0.9,\n",
    "                              tot_digits=4, show=False)\n",
    "        plt.show(fig2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btrex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
