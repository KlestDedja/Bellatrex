{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Bellatrex Tutorial\n\nThis notebook demonstrates how to use **Bellatrex** to explain individual predictions made by Random Forest models.\n\nIt covers all supported prediction tasks:\n- **Binary classification** – `RandomForestClassifier` with a single binary target\n- **Regression** – `RandomForestRegressor` with a single continuous target\n- **Survival analysis** – `RandomSurvivalForest` with time-to-event targets\n- **Multi-label classification** – `RandomForestClassifier` with multiple binary targets\n- **Multi-target regression** – `RandomForestRegressor` with multiple continuous targets\n\nThe workflow is always the same regardless of the task:\n1. Load data and train a Random Forest (or load a pre-trained one)\n2. Pack the model with `pack_trained_ensemble` (optional but recommended for large models)\n3. Create and fit a `BellatrexExplain` instance on training data\n4. Call `.explain(X_test, idx)` for a test sample, then visualise with `.plot_overview()`, `.plot_visuals()`, or `.print_rules_txt()`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport numpy as np\nimport pandas as pd\nimport bellatrex\n\nprint(\"Bellatrex version:\", bellatrex.__version__)\n\nPLOT_GUI = False  # set to True to enable the interactive GUI (requires bellatrex[gui])\n\nroot_folder = os.getcwd()\nprint(\"Working directory:\", root_folder)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sksurv.ensemble import RandomSurvivalForest\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\nfrom bellatrex.datasets import load_mtr_data, load_mlc_data\nfrom bellatrex.datasets import load_survival_data, load_binary_data, load_regression_data\nfrom bellatrex.utilities import get_auto_setup\n\n# Uncomment the dataset that matches the prediction task you want to explore:\n# X, y = load_binary_data(return_X_y=True)      # binary classification\nX, y = load_regression_data(return_X_y=True)     # regression\n# X, y = load_survival_data(return_X_y=True)    # survival analysis\n# X, y = load_mlc_data(return_X_y=True)         # multi-label classification\n# X, y = load_mtr_data(return_X_y=True)         # multi-target regression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1 – Train a Random Forest\n\nDepending on the prediction task detected above, we instantiate and train a compatible Random Forest model.\n`get_auto_setup` inspects the label array `y` and returns the task string (`\"binary\"`, `\"regression\"`, `\"survival\"`, etc.)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "SETUP = get_auto_setup(y)\nprint(\"Detected prediction task 'SETUP':\", SETUP)\n\nif SETUP.lower() == \"survival\":\n    clf = RandomSurvivalForest(n_estimators=100, min_samples_split=10,\n                               n_jobs=-2, random_state=0)\nelif SETUP.lower() in [\"binary\", \"multi-label\"]:\n    clf = RandomForestClassifier(n_estimators=100, min_samples_split=5,\n                                 n_jobs=-2, random_state=0)\nelif SETUP.lower() in [\"regression\", \"multi-target\"]:\n    clf = RandomForestRegressor(n_estimators=100, min_samples_split=5,\n                                n_jobs=-2, random_state=0)\n\nclf.fit(X_train, y_train)\nprint(\"Model fitting complete.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2 – Pack the trained model (optional)\n\n`pack_trained_ensemble` converts the fitted forest into a compact dictionary representation.\nThis is useful when the original `sklearn` model is large or when you want to load a\npre-trained model that was serialised externally (e.g. via `pickle` or `joblib`).\n\nThe packed model is also compatible with the [SHAP](https://shap.readthedocs.io/en/latest/) library."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from bellatrex import pack_trained_ensemble\n\n# pack_trained_ensemble converts the fitted forest into a memory-efficient dictionary.\n# Pass clf_packed (or the original clf) to BellatrexExplain – both are supported.\nclf_packed = pack_trained_ensemble(clf)\nprint(f\"Packed {clf_packed['ensemble_class']} with {len(clf_packed['trees'])} trees.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3 – Fit Bellatrex and explain predictions\n\n`BellatrexExplain` accepts either the original `sklearn`/`sksurv` model or the packed dictionary.\n\nKey constructor parameters:\n- `set_up` – prediction task; `\"auto\"` detects it automatically from the fitted model.\n- `p_grid` – hyperparameter search grid. Bellatrex selects the combination with the highest\n  fidelity to the black-box prediction. Keys: `n_trees`, `n_dims`, `n_clusters`.\n- `verbose` – controls console output (0 = quiet, 1 = summary, ≥3 = detailed).\n\nAfter calling `.fit(X_train, y_train)`, call `.explain(X_test, idx)` for any test sample.\nThe result supports method chaining into the visualisation methods:\n\n| Output method | Description | Task support |\n|---|---|---|\n| `.plot_overview()` | Cluster plot + selected rule trees | All tasks |\n| `.plot_visuals()` | Rule-level bar chart with confidence bands | Single-output only |\n| `.create_rules_txt()` | Save explanation to `.txt` | All tasks |\n| `.print_rules_txt()` | Print explanation to console | All tasks |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from bellatrex import BellatrexExplain, predict_helper\nimport matplotlib.pyplot as plt\n\n# Fit the Bellatrex explainer on training data.\n# p_grid controls how many explanation rules to extract (n_clusters) and other internal\n# hyperparameters. Bellatrex auto-selects the best combination via fidelity to the RF.\nBtrex_fitted = BellatrexExplain(\n    clf_packed,\n    set_up=\"auto\",\n    p_grid={\"n_clusters\": [1, 2, 3]},\n    verbose=1,\n).fit(X_train, y_train)\n\n# Pre-compute training predictions once, used as background distribution in plot_visuals\ny_train_pred = predict_helper(clf, X_train)\n\nN_TEST_SAMPLES = 2\nfor i in range(N_TEST_SAMPLES):\n    print(f\"\\n--- Explaining sample i={i} ---\")\n\n    tuned_method = Btrex_fitted.explain(X_test, i)\n\n    # Plot 1: cluster overview (shows pre-selected trees and selected rules)\n    fig1, axs1 = tuned_method.plot_overview(plot_gui=False)\n    plt.show(fig1)\n\n    # Plot 2: rule-level detail (single-output tasks only)\n    if SETUP.lower() in [\"binary\", \"regression\", \"survival\"]:\n        fig2, axs2 = tuned_method.plot_visuals(\n            plot_max_depth=5,\n            preds_distr=y_train_pred,\n            conf_level=0.9,\n            tot_digits=4,\n            show=False,\n        )\n        plt.show(fig2)\n\n    # Text explanation: save to file and print to console\n    tuned_method.create_rules_txt()\n    tuned_method.print_rules_txt()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btrex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}